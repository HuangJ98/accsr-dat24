{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dir = \"../../../logs/en/asr/evaluate\"\n",
    "folders = {\n",
    "    \"AC_1\": \"version_24\",\n",
    "    \"AC_100\": \"version_32\",\n",
    "    \"AC_10\": \"version_33\",\n",
    "    \"AC_0.1\": \"version_34\",\n",
    "    \"AC_0.01\": \"version_35\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define which accent is standard, which are seen and which are unseen\n",
    "classes = {\n",
    "    \"seen\": [\"us\", \"uk\", \"ca\", \"in\", \"de\", \"au\"],\n",
    "    \"unseen\": [\"hk\", \"sg\", \"sc\", \"nz\", \"ie\", \"za\", \"ni\", \"ph\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load WERs of each file, for each accent\n",
    "wers = dict()\n",
    "for exp, folder in folders.items():\n",
    "    wers[exp] = {k[5:-4]: v for k, v in json.load(open(f\"{exp_dir}/{folder}/avg_wers.json\")).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform dictionary into a numpy array, where one axis represents the accents and another the experiments\n",
    "experiments = list(wers.keys())\n",
    "accents = list(wers[experiments[0]].keys())\n",
    "n_words = np.array([wers[experiments[0]][acc][\"n_words\"] for acc in accents])\n",
    "avg_wers = np.array([[wers[exp][acc][\"avg_wer\"] for exp in experiments] for acc in accents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute means for each class, for each experiment\n",
    "class_indices = {k: [accents.index(acc) for acc in v] for k, v in classes.items()}\n",
    "class_means = {k: np.mean(avg_wers[indices], axis=0) for k, indices in class_indices.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accent / Dialect | AC_1 | AC_100 | AC_10 | AC_0.1 | AC_0.01\n",
      "|---:|---:|---:|---:|---:|---:|\n",
      "za | 6.54 | 8.50 | 6.61 | 6.54 | 6.54\n",
      "sg | 10.51 | 12.37 | 10.48 | 10.36 | 10.38\n",
      "in | 9.41 | 12.02 | 9.38 | 9.21 | 9.19\n",
      "au | 7.53 | 9.68 | 7.56 | 7.46 | 7.44\n",
      "hk | 9.75 | 11.22 | 9.77 | 9.73 | 9.71\n",
      "ie | 7.41 | 8.99 | 7.46 | 7.47 | 7.45\n",
      "uk | 5.87 | 7.11 | 5.85 | 5.74 | 5.75\n",
      "ph | 8.79 | 10.38 | 8.82 | 8.80 | 8.78\n",
      "de | 5.66 | 7.76 | 5.58 | 5.56 | 5.57\n",
      "ni | 7.02 | 8.13 | 7.04 | 6.94 | 6.93\n",
      "us | 5.46 | 7.41 | 5.45 | 5.40 | 5.41\n",
      "ca | 5.35 | 6.93 | 5.34 | 5.31 | 5.32\n",
      "nz | 5.28 | 7.07 | 5.27 | 5.33 | 5.35\n",
      "sc | 32.55 | 36.38 | 32.88 | 33.80 | 33.60\n",
      "mean | 9.08 | 11.00 | 9.11 | 9.12 | 9.10\n",
      "seen mean | 6.55 | 8.49 | 6.53 | 6.44 | 6.45\n",
      "unseen mean | 10.98 | 12.88 | 11.04 | 11.12 | 11.09\n",
      "worst | 32.55 | 36.38 | 32.88 | 33.80 | 33.60\n",
      "3-worst mean. |s 17.61 |s 20.26 |s 17.71 |s 17.96 |s 17.90\n"
     ]
    }
   ],
   "source": [
    "# print the avg. WERs and the means (overall and per class) as a markdown table\n",
    "headers = [\"Accent / Dialect\"] + experiments\n",
    "print((\" | \").join(headers))\n",
    "print(f\"|{'---:|'*len(headers)}\")\n",
    "\n",
    "# print avg. WERs\n",
    "for i in range(len(accents)):\n",
    "    row = [accents[i]] + [f\"{avg_wers[i,j]*100:.2f}\" for j in range(len(experiments))]\n",
    "    print((\" | \").join(row))\n",
    "\n",
    "# print overall means\n",
    "row = [\"mean\"] + [f\"{np.mean(avg_wers[:,i])*100:.2f}\" for i in range(len(experiments))]\n",
    "print((\" | \").join(row))\n",
    "\n",
    "# print class means\n",
    "for key, value in class_means.items():\n",
    "    row = [f\"{key} mean\"] + [f\"{value[i]*100:.2f}\" for i in range(len(experiments))]\n",
    "    print((\" | \").join(row))\n",
    "\n",
    "# print worst avg. WER of each experiment\n",
    "row = [\"worst\"] + [f\"{v*100:.2f}\" for v in np.max(avg_wers, axis=0)]\n",
    "print((\" | \").join(row))\n",
    "\n",
    "# print the avg. of the three worst avg. WERs of each experiment\n",
    "row = [\"3-worst mean.\"] + [f\"{np.mean(np.sort(avg_wers, axis=0)[-3:,i])*100:.2f}\" for i in range(len(experiments))]\n",
    "print((\" |s \").join(row))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accent / Dialect | AC_1 | AC_100 | AC_10 | AC_0.1 | AC_0.01\n",
    "|---:|---:|---:|---:|---:|---:|\n",
    "za | 6.54 | 8.50 | 6.61 | 6.54 | 6.54\n",
    "sg | 10.51 | 12.37 | 10.48 | 10.36 | 10.38\n",
    "in | 9.41 | 12.02 | 9.38 | 9.21 | 9.19\n",
    "au | 7.53 | 9.68 | 7.56 | 7.46 | 7.44\n",
    "hk | 9.75 | 11.22 | 9.77 | 9.73 | 9.71\n",
    "ie | 7.41 | 8.99 | 7.46 | 7.47 | 7.45\n",
    "uk | 5.87 | 7.11 | 5.85 | 5.74 | 5.75\n",
    "ph | 8.79 | 10.38 | 8.82 | 8.80 | 8.78\n",
    "de | 5.66 | 7.76 | 5.58 | 5.56 | 5.57\n",
    "ni | 7.02 | 8.13 | 7.04 | 6.94 | 6.93\n",
    "us | 5.46 | 7.41 | 5.45 | 5.40 | 5.41\n",
    "ca | 5.35 | 6.93 | 5.34 | 5.31 | 5.32\n",
    "nz | 5.28 | 7.07 | 5.27 | 5.33 | 5.35\n",
    "sc | 32.55 | 36.38 | 32.88 | 33.80 | 33.60\n",
    "mean | 9.08 | 11.00 | 9.11 | 9.12 | 9.10\n",
    "seen mean | 6.55 | 8.49 | 6.53 | 6.44 | 6.45\n",
    "unseen mean | 10.98 | 12.88 | 11.04 | 11.12 | 11.09\n",
    "worst | 32.55 | 36.38 | 32.88 | 33.80 | 33.60\n",
    "3-worst mean. | 17.61 | 20.26 | 17.71 | 17.96 | 17.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment folders:\n",
      "\n",
      "- AC_1: training `logs/en/ensemble/train/binary/b7/DAT/version_66`, evaluation `../../logs/en/asr/evaluate/version_24`\n",
      "- AC_100: training `logs/en/ensemble/train/binary/b7/DAT/version_74`, evaluation `../../logs/en/asr/evaluate/version_32`\n",
      "- AC_10: training `logs/en/ensemble/train/binary/b7/DAT/version_75`, evaluation `../../logs/en/asr/evaluate/version_33`\n",
      "- AC_0.1: training `logs/en/ensemble/train/binary/b7/DAT/version_76`, evaluation `../../logs/en/asr/evaluate/version_34`\n",
      "- AC_0.01: training `logs/en/ensemble/train/binary/b7/DAT/version_77`, evaluation `../../logs/en/asr/evaluate/version_35`\n"
     ]
    }
   ],
   "source": [
    "# print the experiment folders of each experiment (both train and eval folders)\n",
    "print(\"Experiment folders:\\n\")\n",
    "for exp, folder in folders.items():\n",
    "    eval_folder = os.path.join(exp_dir, folder)\n",
    "    eval_config = OmegaConf.load(os.path.join(eval_folder, \"config.yaml\"))\n",
    "    train_folder = f'../{eval_config.asr.ckpt.replace(\"/checkpoints/last.ckpt\", \"\")}'\n",
    "    print(f\"- {exp}: training `{train_folder[3:]}`, evaluation `{eval_folder[3:]}`\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bac90b33b2e8bf5368ff2c0ee0f6c7fcb3410fada8b1fda9f71f846ace4b0b44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
