{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dir = \"../../../logs/en/asr/evaluate\"\n",
    "folders = {\n",
    "    \"Fine-tuned_9\": \"version_9\",\n",
    "    \"AC_1\": \"version_48\",\n",
    "    \"AC_2\": \"version_49\",\n",
    "    \"AC_5\": \"version_50\",\n",
    "    \"AC_10\": \"version_24\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define which accent is standard, which are seen and which are unseen\n",
    "classes = {\n",
    "    \"seen\": [\"us\", \"uk\", \"ca\", \"in\", \"de\", \"au\"],\n",
    "    \"unseen\": [\"hk\", \"sg\", \"sc\", \"nz\", \"ie\", \"za\", \"ni\", \"ph\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load WERs of each file, for each accent\n",
    "wers = dict()\n",
    "for exp, folder in folders.items():\n",
    "    wers[exp] = {k[5:-4]: v for k, v in json.load(open(f\"{exp_dir}/{folder}/avg_wers.json\")).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform dictionary into a numpy array, where one axis represents the accents and another the experiments\n",
    "experiments = list(wers.keys())\n",
    "accents = list(wers[experiments[0]].keys())\n",
    "n_words = np.array([wers[experiments[0]][acc][\"n_words\"] for acc in accents])\n",
    "avg_wers = np.array([[wers[exp][acc][\"avg_wer\"] for exp in experiments] for acc in accents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute means for each class, for each experiment\n",
    "class_indices = {k: [accents.index(acc) for acc in v] for k, v in classes.items()}\n",
    "class_means = {k: np.mean(avg_wers[indices], axis=0) for k, indices in class_indices.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accent / Dialect | Fine-tuned_9 | AC_1 | AC_2 | AC_5 | AC_10\n",
      "|---:|---:|---:|---:|---:|---:|\n",
      "za | 6.54 | 6.51 | 6.52 | 6.58 | 6.54\n",
      "sg | 10.41 | 11.07 | 11.09 | 10.47 | 10.51\n",
      "in | 9.21 | 9.30 | 9.30 | 9.34 | 9.41\n",
      "au | 7.47 | 7.53 | 7.52 | 7.61 | 7.53\n",
      "hk | 9.76 | 10.22 | 10.21 | 9.87 | 9.75\n",
      "ie | 7.51 | 7.64 | 7.66 | 7.45 | 7.41\n",
      "uk | 5.78 | 5.80 | 5.80 | 5.90 | 5.87\n",
      "ph | 8.90 | 9.08 | 9.11 | 8.81 | 8.79\n",
      "de | 5.62 | 5.62 | 5.61 | 5.61 | 5.66\n",
      "ni | 6.96 | 6.81 | 6.79 | 7.16 | 7.02\n",
      "us | 5.43 | 5.67 | 5.65 | 5.46 | 5.46\n",
      "ca | 5.36 | 5.51 | 5.49 | 5.37 | 5.35\n",
      "nz | 5.40 | 5.77 | 5.76 | 5.38 | 5.28\n",
      "sc | 33.50 | 33.80 | 33.94 | 33.15 | 32.55\n",
      "mean | 9.13 | 9.31 | 9.32 | 9.15 | 9.08\n",
      "seen mean | 6.48 | 6.57 | 6.56 | 6.55 | 6.55\n",
      "unseen mean | 11.12 | 11.36 | 11.39 | 11.11 | 10.98\n",
      "worst | 33.50 | 33.80 | 33.94 | 33.15 | 32.55\n",
      "3-worst mean. | 17.89 | 18.36 | 18.41 | 17.83 | 17.61\n"
     ]
    }
   ],
   "source": [
    "# print the avg. WERs and the means (overall and per class) as a markdown table\n",
    "headers = [\"Accent / Dialect\"] + experiments\n",
    "print((\" | \").join(headers))\n",
    "print(f\"|{'---:|'*len(headers)}\")\n",
    "\n",
    "# print avg. WERs\n",
    "for i in range(len(accents)):\n",
    "    row = [accents[i]] + [f\"{avg_wers[i,j]*100:.2f}\" for j in range(len(experiments))]\n",
    "    print((\" | \").join(row))\n",
    "\n",
    "# print overall means\n",
    "row = [\"mean\"] + [f\"{np.mean(avg_wers[:,i])*100:.2f}\" for i in range(len(experiments))]\n",
    "print((\" | \").join(row))\n",
    "\n",
    "# print class means\n",
    "for key, value in class_means.items():\n",
    "    row = [f\"{key} mean\"] + [f\"{value[i]*100:.2f}\" for i in range(len(experiments))]\n",
    "    print((\" | \").join(row))\n",
    "\n",
    "# print worst avg. WER of each experiment\n",
    "row = [\"worst\"] + [f\"{v*100:.2f}\" for v in np.max(avg_wers, axis=0)]\n",
    "print((\" | \").join(row))\n",
    "\n",
    "# print the avg. of the three worst avg. WERs of each experiment\n",
    "row = [\"3-worst mean.\"] + [f\"{np.mean(np.sort(avg_wers, axis=0)[-3:,i])*100:.2f}\" for i in range(len(experiments))]\n",
    "print((\" | \").join(row))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accent / Dialect | AC_1 | AC_2 | AC_5 | AC_10\n",
    "|---:|---:|---:|---:|---:|\n",
    "Southern African (South Africa, Zimbabwe, Namibia) | 6.51 | 6.52 | 6.58 | 6.54\n",
    "Singaporean English | 11.07 | 11.09 | 10.47 | 10.51\n",
    "India and South Asia (India, Pakistan, Sri Lanka) | 9.30 | 9.30 | 9.34 | 9.41\n",
    "Australian English | 7.53 | 7.52 | 7.61 | 7.53\n",
    "Hong Kong English | 10.22 | 10.21 | 9.87 | 9.75\n",
    "Irish English | 7.64 | 7.66 | 7.45 | 7.41\n",
    "England English | 5.80 | 5.80 | 5.90 | 5.87\n",
    "Filipino | 9.08 | 9.11 | 8.81 | 8.79\n",
    "German English,Non native speaker | 5.62 | 5.61 | 5.61 | 5.66\n",
    "Northern Irish | 6.81 | 6.79 | 7.16 | 7.02\n",
    "United States English | 5.67 | 5.65 | 5.46 | 5.46\n",
    "Canadian English | 5.51 | 5.49 | 5.37 | 5.35\n",
    "New Zealand English | 5.77 | 5.76 | 5.38 | 5.28\n",
    "Scottish English | 33.80 | 33.94 | 33.15 | 32.55\n",
    "mean | 9.31 | 9.32 | 9.15 | 9.08\n",
    "seen mean | 6.57 | 6.56 | 6.55 | 6.55\n",
    "unseen mean | 11.36 | 11.39 | 11.11 | 10.98\n",
    "worst | 33.80 | 33.94 | 33.15 | 32.55\n",
    "3-worst mean. | 18.36 | 18.41 | 17.83 | 17.61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment folders:\n",
      "\n",
      "- Fine-tuned_9: training `logs/en/asr/train/version_11`, evaluation `../../logs/en/asr/evaluate/version_9`\n",
      "- AC_1: training `logs/en/ensemble/train/binary/b7/DAT/version_90`, evaluation `../../logs/en/asr/evaluate/version_48`\n",
      "- AC_2: training `logs/en/ensemble/train/binary/b7/DAT/version_91`, evaluation `../../logs/en/asr/evaluate/version_49`\n",
      "- AC_5: training `logs/en/ensemble/train/binary/b7/DAT/version_92`, evaluation `../../logs/en/asr/evaluate/version_50`\n",
      "- AC_10: training `logs/en/ensemble/train/binary/b7/DAT/version_66`, evaluation `../../logs/en/asr/evaluate/version_24`\n"
     ]
    }
   ],
   "source": [
    "# print the experiment folders of each experiment (both train and eval folders)\n",
    "print(\"Experiment folders:\\n\")\n",
    "for exp, folder in folders.items():\n",
    "    eval_folder = os.path.join(exp_dir, folder)\n",
    "    eval_config = OmegaConf.load(os.path.join(eval_folder, \"config.yaml\"))\n",
    "    train_folder = f'../{eval_config.asr.ckpt.replace(\"/checkpoints/last.ckpt\", \"\")}'\n",
    "    print(f\"- {exp}: training `{train_folder[3:]}`, evaluation `{eval_folder[3:]}`\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bac90b33b2e8bf5368ff2c0ee0f6c7fcb3410fada8b1fda9f71f846ace4b0b44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
